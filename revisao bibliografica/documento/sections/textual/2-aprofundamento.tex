\section{Fundamentação teórica}

Durante a revisão da literatura, foram identificados modelos e arquiteturas relevantes. No entanto, observa-se que muitos deles derivam de estruturas fundamentais semelhantes, incorporando otimizações, variações ou módulos adicionais para aprimorar o desempenho. Entre os conceitos mais releventes destacam-se:

\subsection{Aprendizado profundo}

O aprendizado profundo é um subcampo do aprendizado de máquina que se baseia no uso de redes neurais artificiais com múltiplas camadas, capazes de modelar relações complexas em dados. Ao contrário de algoritmos tradicionais de aprendizado de máquina, que frequentemente dependem de extração manual de características, o aprendizado profundo consegue aprender automaticamente representações hierárquicas dos dados.

No contexto de imagens, por exemplo, redes profundas podem aprender a reconhecer padrões visuais em diferentes níveis de abstração: camadas iniciais detectam bordas e contornos, camadas intermediárias capturam formas e texturas, e camadas mais profundas identificam objetos completos ou padrões de defeitos. Fazendo com que o modelo também identifique defeitos sutis.

As redes profundas são compostas por várias unidades chamadas neurônios artificiais, organizadas em camadas. Cada neurônio realiza operações matemáticas sobre os dados de entrada, aplicando pesos e funções de ativação não lineares, o que possibilita à rede modelar relações complexas entre variáveis. O treinamento de uma rede profunda envolve a otimização desses pesos, geralmente por meio do algoritmo de retropropagação, que ajusta os parâmetros para minimizar o erro entre a saída prevista e a saída real.

\begin{figure}[H]
    \centering
    \caption{Exemplificação das múltiplas camadas de um modelo de aprendizado profundo}
    \includegraphics[width=0.5\linewidth]{images/aprendizado profundo.png}\\
    \fonteimagem{Fonte: \textcite{researchgate2025}}
    \label{fig:aprendizado profundo}
\end{figure}

\subsection{Rede neural convolucional}

As Redes Neurais Convolucionais (CNNs) são uma arquitetura específica de aprendizado profundo projetada para lidar com dados estruturados espacialmente, onde o valor de um elemento está relacionado com seus vizinhos, por exemplo, imagens.

Uma CNN típica é composta por:

\begin{itemize}    
    \item \textbf{Uma camada de Entrada:} Recebem os dados em formato de matriz.
    
    \item \textbf{N Camadas Convolucionais:} Aplicam filtros que detectam padrões locais (Kernels), como bordas, curvas e texturas. Cada filtro responde a um tipo específico de característica, produzindo mapas de características que destacam essas informações.
    Nesses mapas, são adicionados bias e aplicadas funções de ativação (ex: ReLU), com o intuito de introduzir não linearidade ao sistema e permitir o aprendizado de padrões mais complexos.
    
    \item \textbf{N Camadas de Agrupamento:} Reduzem a dimensionalidade da matriz resultante (mapas de ativação), preservando informações importantes e tornando o modelo menos sensível a pequenas variações na posição dos objetos.
    
    \item \textbf{Uma Camada Totalmente Conectadas:} Recebem as características extraídas em forma de um vetor, processa elas e sãoe produzem a saída final.
\end{itemize}
\begin{figure}[H]
    \centering
    \caption{Exemplificação de uma rede neural convolucional}
    \includegraphics[width=0.8\linewidth]{images/cnn.png}\\
    \fonteimagem{Fonte: \textcite{inbook}}
    \label{fig:rede neural convolucional}
\end{figure}

No caso da detecção de anomalias em trilhos ferroviários, as CNNs permitem que o modelo aprenda automaticamente padrões de falhas, como deformações, fissuras, ou desgaste, sem a necessidade de extração manual de características.

\subsection{Transferência de aprendizado}

Um dos principais desafios para o uso aprendizado profundo é a necessidade de grandes volumes de dados rotulados para treinar redes neurais com desempenho satisfatório.
Esse problema é ainda mais evidente no meio acadêmico, onde bancos de dados extensos nem sempre estão disponíves, tornando inviável o treinamento de modelos complexos a partir do zero
Para contornar essa limitação, emprega-se a técnicas de transferência de aprendizado.

A transferência de aprendizado consiste em reutilizar o conhecimento adquirido por um modelo previamente treinado em um grande dataset genérico, como ImageNet ou COCO, aplicando-o a uma nova tarefa que dispõe de uma quantidade limitada de dados.
Esses modelos pré-treinados já aprenderam a identificar padrões visuais fundamentais, como bordas, formas e texturas,  que tendem a ser úteis em diversos domínios.

Na prática, o processo de transferência de aprendizado pode ser divido em duas etapas principais:

\begin{enumerate}
    \item \textbf{Congelamento do modelo base:} o modelo pré-treinado, frequentemente chamado de modelo professor, mantém seus pesos nas camadas iniciais e intermediárias, preservando a capacidade de extrair padrões gerais já aprendidos.
    \item \textbf{Adaptação à nova tarefa:} as camadas finais do modelo são modificadas ou substituidas para se ajustarem ao novo problema. Essas camadas são então treinadas com o dataset específico, permitindo que o modelo aprenda características relevantes para a tarefa alvo sem necessidade de treinamento integral. Em modelos híbridos, essa etapa pode incluir a combinação de arquiteturas, como utilizar a saída da camada totalmente conectada de uma CNN como entrada para um classificador externo, por exemplo uma SVM.
\end{enumerate}

\begin{figure}[H]
    \centering
    \caption{Exemplificação de transferencia de aprendizado}
    \includegraphics[width=0.8\linewidth]{images/transferencia de aprendizado.jpg}\\
    \fonteimagem{Fonte: \textcite{freetimelearning_transfer_learning}}
    \label{fig:transferencia de aprendizado}
\end{figure}

Na Figura \ref{fig:transferencia de aprendizado} é demonstrado a diferença do processo de treinamento de uma CNN treinada do zero e treinamento de uma CNN pré-treinada, sendo necessário apenas modificar camada de saída da rede e realizar o aperfeiçoamento dos parâmetros.

Neste trabalho, será utilizada uma redes neural convolucional pré-treinada para aproveitar o conhecimento adquirido por grandes modelos treinados em bases extensas e minimizar os impactos causados pelo uso de um dataset reduzido.

A arquitetura escolhida foi a MobileNetV3, sendo esta uma melhoria do mobileNetV2 utilizada por \textcite{MobileNetV3} em seu trabalho de identificação de defeitos em pinos de fixação e amplamente recomendada para tratar de datasets pequenos, como é o caso.

\subsection{Transformadores visuais}

Os Transformadores Visuais (ViTs) representam uma abordagem mais recente no processamento de imagens, inspirada nos Transformers utilizados originalmente em tarefas de linguagem natural. Enquanto as CNNs focam em padrões locais, os transformadores capturam relações globais na imagem por meio de mecanismos de atenção, permitindo que o modelo considere o contexto completo ao tomar decisões.

O funcionamento básico de um Vision Transformer envolve:

\begin{itemize}
    \item Divisão da imagem em patches menores.
    
    \item Transformação de cada patch em vetores de embedding, que codificam informações visuais.
    
    \item Passagem dos embeddings por camadas de autoatenção, que ponderam a importância relativa de cada patch em relação aos outros, integrando contexto global.
    
    \item Classificação ou detecção baseada nos embeddings processados, permitindo identificar padrões complexos e sutis, como pequenas fissuras ou deformações.
\end{itemize}

\begin{figure}[H]
    \centering
    \caption{Exemplificação do funcionamento de um transformador visual}
    \includegraphics[width=0.8\linewidth]{images/transformador viusal.png}\\
    \fonteimagem{Fonte: \textcite{article}}
    \label{fig:transformador visual}
\end{figure}

Transformadores visuais têm se mostrado altamente eficazes em tarefas onde a variabilidade de cenários é grande ou os datasets são limitados, pois conseguem aproveitar melhor a informação contextual e evitar confusões causadas por objetos próximos ou fundos complexos.

Como observado no trabalho de \textcite{s24103247}, modelos híbridos, combinando CNNs e ViTs, também têm sido utilizados para aproveitar a extração local de CNNs e a consciência global dos transformadores, alcançando desempenho superior em detecção de defeitos ferroviários.
Isso é feito, treinando CNNs em grandes datasets de imagens e utilizando-as para treinar os ViTs.

\subsection{SVM}
Embora máquinas de vetores de suporte (SVM) não sejam técnicas de aprendizado profundo, será utilizado SVM de modelo híbrido. Para isso, a CNN pré-treinada será utilizada como extratora de características para a SVM. As últimas camadas convolucionais irão produzir vetores representativos do conteúdo visual da imagem, que serão utilizados como input pela SVM, evitando a necessidade de extração de características manuais.

Ela será utilizada como baseline para os outros métodos, visto que, métodos de aprendizado profundo devem produzir resultados melhores que métodos tradicionais como SVM.

\begin{figure}[H]
    \centering
    \caption{Exemplificação do funcionamento de uma arquitetura SVM+CNN}
    \includegraphics[width=0.8\linewidth]{images/SVMCNN.png}\\
    \fonteimagem{Fonte: \textcite{article2}}
    \label{fig:SVM}
\end{figure}
